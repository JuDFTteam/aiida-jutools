{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Structure Property visualizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the second of two deliverables for the SiSc-Lab2020 project.\n",
    "\n",
    "Authors = Sijie Luo and Anna Garoufali\n",
    "\n",
    "Supervisors: Dr. Jens Bröder, Dr. Daniel Wortmann, Johannes Wasmer, Prof. Dr. Stefan Blügel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Usage: adjust user constants in code cell 'User constants'.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# User constants\n",
    "aiida_profile_name = \"wasmer\"\n",
    "enable_autoreload = True # disable for timings\n",
    "\n",
    "# ---\n",
    "\n",
    "# selected workflow identifier for 'single workflow' analysis sections and interactive plot.\n",
    "# this identifier specifies [workflow type: TODO] and that type's version.\n",
    "# notebook will inspect all database workflow nodes of this type and version.\n",
    "# available identifiers are listed in helpers.py dict MAP values.\n",
    "\n",
    "# # example for database with aiida-fleur workflows\n",
    "# single_workflow_identifier = 'workflow_0.4.2'\n",
    "\n",
    "# example for database with aiida-kkr workflows\n",
    "single_workflow_identifier = 'parser_0.3.2'\n",
    "\n",
    "\n",
    "# ---\n",
    "\n",
    "# # for interactive plot of predefined workflow. \n",
    "# # make sure attributes are defined in helpers.predefined_workflows for selected workflow.\n",
    "\n",
    "# # example for database with aiida-fleur workflows only\n",
    "# xcol = 'total_energy'\n",
    "# ycol = 'distance_charge'\n",
    "\n",
    "# example for database with aiida-kkr workflows only\n",
    "xcol = 'alat'\n",
    "ycol = 'emin_minus_efermi'\n",
    "# xcol = 'fermi_energy'\n",
    "# ycol = 'dos_at_fermi_energy'\n",
    "\n",
    "# ---\n",
    "\n",
    "# for timings file\n",
    "# database_size: in terminal, connect to postgres database via psql and execute '\\l+'.\n",
    "notebook_name = \"D2\"\n",
    "database_name = \"wasmer_medium_size\"\n",
    "database_size = 431 # MB\n",
    "database_description = [\n",
    "    \"800 Impurity (defect atoms) embeddings into different elemental host crystals with aiida-kkr.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if enable_autoreload:\n",
    "    %load_ext autoreload\n",
    "    %autoreload 2\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# python imports:\n",
    "from collections import Counter\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#from pprint import pprint\n",
    "\n",
    "#from aiida_jutools.sisc_lab import helpers\n",
    "from bokeh.io import output_notebook\n",
    "# init bokeh\n",
    "output_notebook()\n",
    "\n",
    "# aiida imports:\n",
    "from aiida import load_profile\n",
    "profile = load_profile(aiida_profile_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # project imports prep (for johannes, else comment out)\n",
    "\n",
    "# # add project module to sys.path\n",
    "# import sys\n",
    "# from pathlib import Path\n",
    "\n",
    "# def add_to_sys_path(path:Path):\n",
    "#     if str(path) not in sys.path:\n",
    "#         sys.path.append(str(path))\n",
    "\n",
    "# # load developer's code: general package\n",
    "# project_dir = Path(\"/Users/wasmer/src/aiida-jutools/\")\n",
    "# add_to_sys_path(project_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init timer for timings:\n",
    "timer = helpers.Timer(notebook_name=notebook_name, \n",
    "                      database_name=database_name,\n",
    "                      database_size=database_size)\n",
    "timer.DATABASE_DESCRIPTION = database_description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "helpers.print_bold(f\"This notebook/dashboard will visualize the contents from the database of profile {profile.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check workflows and versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timing_name = \"Workflows info\"\n",
    "timer.start(timing_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing: Set formula attributes for all the structure nodes\n",
    "helpers.set_structure_formula()\n",
    "\n",
    "# workflow_name = 'fleur_scf_wc' # Filter workflow\n",
    "# workflow_filters = {'attributes.process_label' : {'==' : workflow_name}}\n",
    "# workflowdictlst = helpers.get_structure_workflow_dict(workflow_filters=workflow_filters)\n",
    "#or\n",
    "workflow_name = None # No restriction. Querying by default\n",
    "workflowdictlst, versionslst = helpers.get_structure_workflow_dict(timing=True, check_version=True)\n",
    "\n",
    "print(\"Number of the workflows: \", len(workflowdictlst), '\\n')\n",
    "print(\"Workflows: \")\n",
    "workflowdictlst[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers import MAP\n",
    "from helpers import predifined_workflow\n",
    "versions = [key for key,val in versionslst]\n",
    "versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if single_workflow_identifier not in versions:\n",
    "    raise NotImplementedError(f\"D2 is not implemented for the specified single workflow identifier {single_workflow_identifier}.\"\n",
    "                             f\"Please add this identifier to {helpers.__name__} dictionary 'MAP' and list 'predefined_workflows'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timer.stop(timing_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Structure nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install openpyxl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single workflow version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timing_name = \"Preprocess structures single workflow version\"\n",
    "timer.start(timing_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "structure_project_single=['uuid', 'extras.formula']\n",
    "structure_nodes = helpers.generate_structure_property_pandas_source(\n",
    "            version=single_workflow_identifier,\n",
    "            workflow_name=workflow_name,\n",
    "            structure_project=structure_project_single,\n",
    "            filename=f\"structure_properties_{MAP[single_workflow_identifier]}.json\")\n",
    "#structure_nodes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timer.stop(timing_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple workflow versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timing_name = \"Prepare Structure multiple workflow versions\"\n",
    "timer.start(timing_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "filename='structure_properties_all.xlsx'\n",
    "excel_writer = pd.ExcelWriter(filename)\n",
    "\n",
    "for version in versions:    \n",
    "    structure_project_multiple=['uuid', 'extras.formula']\n",
    "    structure_nodes = helpers.generate_structure_property_pandas_source(\n",
    "                version=version,\n",
    "                workflow_name=workflow_name, \n",
    "                structure_project=structure_project_multiple)\n",
    "    print(structure_nodes)\n",
    "    structure_nodes.to_excel(excel_writer, sheet_name=MAP[version], index=False)\n",
    "\n",
    "excel_writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timer.stop(timing_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dict nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single workflow version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timing_name = \"Prepare Dict single workflow version\"\n",
    "timer.start(timing_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Single workflow version\n",
    "dict_project_single = predifined_workflow.get_workflow(MAP[single_workflow_identifier]).projections\n",
    "dict_nodes = helpers.generate_dict_property_pandas_source(\n",
    "        workflow_name=workflow_name,\n",
    "        version=single_workflow_identifier,\n",
    "        dict_project=dict_project_single, \n",
    "        filename=f\"dict_properties_{MAP[single_workflow_identifier]}.json\")\n",
    "#dict_nodes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timer.stop(timing_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if user constants xcol, ycol are present in selected single workflow's attributes\n",
    "def is_attr_in_single_workflow_attributes(attr):\n",
    "    return any([attr in attr_name for attr_name in dict_project_single])\n",
    "if not is_attr_in_single_workflow_attributes(xcol) or not is_attr_in_single_workflow_attributes(ycol):\n",
    "    import json\n",
    "    raise NotImplementedError(f\"Interactive plot columns xcol='{xcol}' and ycol='{ycol}' are not listed in the selected single \"\n",
    "                             f\"workflow identifier '{single_workflow_identifier}''s attributes. If they should, please adjust \"\n",
    "                             f\"respective entry in {helpers.__name__} list 'predefined_workflows'. \"\n",
    "                             f\"Attributes defined there for this workflow are: {json.dumps(dict_project_single, indent=4)}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple workflow versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timing_name = \"Prepare Dict multiple workflow versions\"\n",
    "timer.start(timing_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename='dict_properties_all.xlsx'\n",
    "excel_writer = pd.ExcelWriter(filename)\n",
    "\n",
    "for version in versions:\n",
    "    dict_project_multiple = predifined_workflow.get_workflow(MAP[version]).projections\n",
    "    dict_nodes = helpers.generate_dict_property_pandas_source(\n",
    "            workflow_name=workflow_name,\n",
    "            version=version,\n",
    "            dict_project=dict_project_multiple)\n",
    "#     print(dict_nodes)\n",
    "    dict_nodes.to_excel(excel_writer, sheet_name=MAP[version], index=False)\n",
    "\n",
    "excel_writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timer.stop(timing_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine two kind of nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single workflow version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timing_name = \"Join data single workflow version\"\n",
    "timer.start(timing_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "structure_project_single=['uuid', 'extras.formula']\n",
    "dict_project_single = predifined_workflow.get_workflow(MAP[single_workflow_identifier]).projections\n",
    "combinednodes = helpers.generate_combined_property_pandas_source(\n",
    "        workflow_name=workflow_name, \n",
    "        version=single_workflow_identifier,\n",
    "        structure_project=structure_project_single,\n",
    "        dict_project=dict_project_single,\n",
    "        filename=f\"combined_properties_{MAP[single_workflow_identifier]}.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timer.stop(timing_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = helpers.read_json_file('combined_properties_wf_0_4_2.json')\n",
    "df_single = helpers.read_json_file(f\"combined_properties_{MAP[single_workflow_identifier]}.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_single[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple workflow versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timing_name = \"Join data multiple workflow versions\"\n",
    "timer.start(timing_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename='combined_properties_all.xlsx'\n",
    "excel_writer = pd.ExcelWriter(filename)\n",
    "\n",
    "for version in versions:\n",
    "    structure_project_multiple=['uuid', 'extras.formula']\n",
    "    dict_project_multiple = predifined_workflow.get_workflow(MAP[version]).projections\n",
    "    combined_nodes = helpers.generate_combined_property_pandas_source(\n",
    "            workflow_name=workflow_name, \n",
    "            version=version,\n",
    "            structure_project=structure_project_multiple,\n",
    "            dict_project=dict_project_multiple)\n",
    "#     print(combined_nodes)\n",
    "    combined_nodes.to_excel(excel_writer, sheet_name=MAP[version], index=False)\n",
    "\n",
    "excel_writer.save()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timer.stop(timing_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Interactive plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check data source before plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single workflow version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timing_name = \"Join data single workflow version\"\n",
    "timer.start(timing_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = helpers.read_json_file('combined_properties_wf_0_4_2.json')\n",
    "df_single = helpers.read_json_file(f\"combined_properties_{MAP[single_workflow_identifier]}.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_single"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df_single, xdata, ydata = helpers.filter_missing_value(df_single, xcol, ycol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timer.stop(timing_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple workflow versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timing_name = \"Join data multiple workflow versions\"\n",
    "timer.start(timing_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = helpers.read_excel_file('combined_properties_all.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers import INVMAP\n",
    "\n",
    "df_all, OPTIONS_all, UNITS_all = {}, {}, {}\n",
    "versions, mversions = [], []\n",
    "for key, df in dfs.items():\n",
    "    df = helpers.filter_unavailable_df(df)\n",
    "    if not df.empty:\n",
    "        df_all[key] = df\n",
    "        OPTIONS_all[key], UNITS_all[key] = helpers.get_attrs_and_units(df)\n",
    "        mversions.append(key)\n",
    "        versions.append(INVMAP[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timer.stop(timing_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interactive plot by Bokeh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_workflow_identifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timing_name = \"Interactive plot\"\n",
    "timer.start(timing_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataframe from multiple workflow versions de/serialization\n",
    "# DEVNOTE: wasmer: single workflow version seems broken\n",
    "df = dfs[MAP[single_workflow_identifier]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAP[single_workflow_identifier]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from single workflow version data (json)\n",
    "helpers.bokeh_struc_prop_vis(df, xcol, ycol, \n",
    "                            output_filename=\"vis_wf042.html\", axis_type=['linear', 'linear'], nbins=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timer.stop(timing_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interactive plot using Bokeh server application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In vscode terminal:\n",
    "# bokeh serve --show --port 5001 bokehplotting.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################\n",
    "# save timings\n",
    "timer.save(silent=False)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Hide code",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "12px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  },
  "toc-autonumbering": true,
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
