{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistical birds eye view of the contents in an AiiDAdb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the first of two deliverable for the SiSc-Lab2020 project.\n",
    "\n",
    "Authors = \n",
    "\n",
    "Supervisors: Jens Bröder, Dr. Daniel Wortmann, Johannes Wasmer, Prof. Dr. Stefan Blügel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instructions by supervisors\n",
    "\n",
    "## Jens\n",
    "a= \"\"\"\n",
    "You have to implement this notebook.\n",
    "\n",
    "In the end only text (markdown) cells and output results of code cells should be seen if one hides the code cells (hide_code extension).\n",
    "\n",
    "That can easily exported into a nice pdf file (google it, probably will find sth with `nbconvert`).\n",
    "\n",
    "Also the amount of python code in this notebook should be minimal.\n",
    "\n",
    "Rather, export the functions you use to python file(s) and import them here (hide complexity).\n",
    "\n",
    "Optional dump query results in a file, from which results will be reread for speed, i.e cache results.\n",
    "\"\"\"\n",
    "\n",
    "## Johannes\n",
    "a = '''\n",
    "After talking with Jens about it, here are some additional thoughts on the code structure and implementation, for both deliverables.\n",
    "\n",
    "The **primary** goal is of course that the code should work, produce nice output (and helpful error messages), obviously.\n",
    "\n",
    "The **secondary** goal is speed. How long do you expect your code to run on a dataset of a given size? Are there multiple paths to a goal, but with differing performance?\n",
    "\n",
    "You can break the runtime down into several steps: data acquisition, data transformation (or preprocessing), data analysis, data visualization. In this project, we will rename/replace these steps to: **querying, de-/serialization, analysis=visualization**.\n",
    "\n",
    "**Querying the database.** Performance considerations:\n",
    "- Performance measurement: use the magics `%time` and `%timeit`.\n",
    "- Query evaluations: queries (in general) use 'lazy evaluation'.\n",
    "  - *Query building* methods build the query but do not execute it. These are chainable methods like `append()`, `get_outgoing()`, etc.\n",
    "  - *Query execution* methods send the query to the database to be evaluated. There are two kinds:\n",
    "    - non-iterator methods: e.g. `all()`, `first()`, etc. These return a result `list`: all items are loaded into memory.\n",
    "    - iterator methods: e.g. `iterall()`, `iterdict()`. These return a result `Generator`: only one item at a time is loaded into memory.\n",
    "    \n",
    "**De-/serialization**, i.e. writing and reading it to/from a file. *Keep in mind: if you come to the conclusion this is unnecessary, then justify it!* Considerations:\n",
    "- Necessity: we assume 'yes'. So you need serialization/deserialization routine(s).\n",
    "- Code design: we recommend to write a serializer that moves *all* data needed from aiida to file (perform query & serialization). Then the visualization methods are decoupled from aiida and load data from that file. Advantages: a) only needs to be called when data in database changed, b) similar queries for different visualizations can be performed only once. One design option is this:\n",
    "  ```python\n",
    "  serialize = sisclab.Serializer(profile)\n",
    "  serialize.to_file(filepath)\n",
    "  visualize = sisclab.Visualizer(filepath)\n",
    "  visualize.histogram(cumulative=True, plot_options)\n",
    "  # plots histogram\n",
    "  ```\n",
    "- Serialization format: there are two practical options (maybe more):\n",
    "  - `dict`: tree-like. JSON format. One `dict` per file. choose key-value (nested?) based on use-case. in general, `uuid` is a good key.\n",
    "  - `pandas.Dataframe`: could be preferrable in some cases.\n",
    "- Serialization location:\n",
    "  - one file or several files?\n",
    "  - we recommend to de/serialize from/to `sisclab/data/` folder. It is included in the project's `.gitignore` file, so nothing in it gets committed to/from git (git is for code, not for data; the code generates the data).\n",
    "- Transformation:\n",
    "  - if needed, decide where to put needed data transformations (before serialization or after deserialization) to minimize them.\n",
    "- Deserialization: \n",
    "  - a class (as above) might help to define the deserialization format only once for all visualization methods.\n",
    "  \n",
    "\n",
    "**Visualization**:\n",
    "- Prefer `bokeh` to `matplotlib` or other libs wherever possible, unless you have a good justification.\n",
    "- In `D1`, static plots are okay, interactive plots are a bonus.\n",
    "- Lists results (when plot is overkill) will look nicer in a notebook if they are a `pandas.Series` or `pandas.Dataframes`.\n",
    "- Think about function signatures. Can you generalize them to make a nice interface? For example, a signature for SubtaskD1.c might look like this:\n",
    "  ```python\n",
    "  def node_type_summary(user_list : list = [], node_basetype : Node = Data,\n",
    "                        chart_type : bokeh.chart_type = bokeh.pie_chart, plot : bool = True):\n",
    "    \"\"\"\n",
    "    :param user_list: list of users. empty list = all users = default.\n",
    "    :param node_basetype: subdivides chart into subtypes. Valid base type examples: ProcessNode, CalculationNode, WorkflowNode, Data, ArrayData.\n",
    "    :param chart_type: bokeh visualization type. pie chart = default.\n",
    "    :param plot: True: show plot, don't return data. False: don't plot, return data.\n",
    "    :return: stats: a dictionary {node_subtype : node_count}, insertion-order sorted in descending order.\n",
    "    :rtype: dict.\n",
    "    \"\"\"\n",
    "  ```\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# magics:\n",
    "# # autoreload imports. \n",
    "# # intent: if i change sth in import, i don't have to restart kernel. enable only for development.\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# # choose matplotlib backend. backend 'notebook' allows interactive plots if your env allows it.\n",
    "%matplotlib notebook\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# python imports:\n",
    "from collections import Counter\n",
    "import time\n",
    "#from pprint import pprint\n",
    "\n",
    "#%pylab inline\n",
    "#figuresize=(18, 4)\n",
    "from collections import Counter\n",
    "from math import pi\n",
    "import pandas as pd\n",
    "from bokeh.io import output_file,output_notebook, show\n",
    "from bokeh.layouts import column\n",
    "from bokeh.palettes import Category20c\n",
    "from bokeh.plotting import figure\n",
    "from bokeh.transform import cumsum\n",
    "from bokeh.models import Legend,LegendItem\n",
    "\n",
    "# aiida imports:\n",
    "from aiida import load_profile\n",
    "profile = load_profile()\n",
    "\n",
    "# ggf add futher imports\n",
    "from aiida.orm import QueryBuilder as QB\n",
    "from aiida.orm import Node, User, CalcJobNode, Computer, Code\n",
    "from aiida.plugins import DataFactory\n",
    "\n",
    "from aiida.common.constants import elements as PeriodicTableElements\n",
    "\n",
    "# project imports:\n",
    "import helpers\n",
    "# from aiida_jutools.sisc_lab import helpers\n",
    "# from aiida_jutools.sisc_lab import HelpersPackage\n",
    "# equivalent ('.' is the sisc_lab directory):\n",
    "# from . import helpers\n",
    "# alternative:\n",
    "# from .helpers import print_bold\n",
    "# from .helpers import * ('*' import everything; use of '*' is considered bad style)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (example:)\n",
    "helpers.print_bold(f\"This notebook/dashboard will visualize the contents from the database of profile {profile.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Database overview:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SubtaskD1.a: Node information\n",
    "#Task:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query for all nodes\n",
    "print('Information on nodes in the DB: \\n')\n",
    "now = time.strftime(\"%c\")\n",
    "print('last executed on {}'.format(now))\n",
    "q = QB()\n",
    "q.append(Node, project=['id', 'ctime', 'mtime', 'node_type'], tag='node')\n",
    "q.append(User, with_node='node', project='email')\n",
    "# TODO: execute query here\n",
    "t = time.time()\n",
    "elapsed = time.time() - t\n",
    "res = q.all()\n",
    "totalnodes = len(res)\n",
    "print(\"Total number of nodes in the database: {} (retrieved in {} s.)\".format(totalnodes, elapsed))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User information:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SubtaskD1.b: Users\n",
    "a = '''\n",
    "Task: print out a list of Users and how many nodes belong to them\n",
    "\n",
    "for example\n",
    "\n",
    "```\n",
    "Users:\n",
    "- j.broeder@fz-juelich.de created 182 nodes\n",
    "- tests@aiida.mail created 104 nodes\n",
    "```\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = Counter([r[4] for r in res])\n",
    "print(\"Users:\")\n",
    "for count, email in sorted((v, k) for k, v in users.items())[::-1]:\n",
    "    print(\"* {} created {} nodes\".format(email, count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Node types distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SubtaskD1.c: Node types\n",
    "a = '''\n",
    "Task: plot node information in two pie chart plots\n",
    "\n",
    "One showing what data nodes there (with their lowest class names(node_type)) I.e Dict, K-pointsData, CifData, FleurinpData...\n",
    "\n",
    "And one chart showning the process nodes, (with their lowest class names(process_type) i.e CalcjobNodes: FleurCalcjob, FleurinputgenCalcjob, ...\n",
    "\n",
    "WorkChain nodes: FleurSCFWorkchain, FleurBandDosWorkchain, ..., calcfunctions, and workfunction nodes are fine to not show the lowest class names\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#node types\n",
    "types = Counter([r[3] for r in res])\n",
    "print(\"Node types:\")\n",
    "\n",
    "for count, typestring in sorted((v, k) for k, v in types.items())[::-1]:\n",
    "    print(\"* {}: {} nodes\".format(typestring, count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split data nodes and process nodes\n",
    "labelst_1,labelst_2=[],[]\n",
    "sizest_1,sizest_2=[],[]\n",
    "#labelst = [label.split('.')[0]=='data' for label in types.keys()]\n",
    "#sizest = [nnodes for nnodes in types.values()]\n",
    "for k,v in types.items():\n",
    "    if k.split('.')[0]=='data':\n",
    "        labelst_1.append(k.split('.')[-2])\n",
    "        sizest_1.append(v)\n",
    "    elif k.split('.')[0]=='process':\n",
    "        labelst_2.append(k.split('.')[-2])\n",
    "        sizest_2.append(v)\n",
    "        \n",
    "#plot data nodes\n",
    "#output_file(\"pie.html\")\n",
    "output_notebook()\n",
    "x = dict(zip(labelst_1,sizest_1)) \n",
    "data=pd.DataFrame.from_dict(dict(x),orient='index').reset_index().rename(index=str,columns={0:'value','index':'data_nodes'})\n",
    "data['angle'] = data['value']/sum(x.values()) * 2*pi\n",
    "data['color'] = Category20c[len(x)]\n",
    "p = figure(plot_height=350, title=\"Data Nodes\", toolbar_location=None,\n",
    "           tools=\"hover\", tooltips=\"@data_nodes: @value\")\n",
    "p.wedge(x=0, y=1, radius=0.4,\n",
    "        start_angle=cumsum('angle', include_zero=True), end_angle=cumsum('angle'),\n",
    "        line_color=\"white\", fill_color='color', legend_field='data_nodes', source=data)\n",
    "p.axis.axis_label=None\n",
    "p.axis.visible=False\n",
    "p.grid.grid_line_color = None \n",
    "#show(p)                        \n",
    "\n",
    "#plot process node\n",
    "\n",
    "x1 = dict(zip(labelst_2,sizest_2)) \n",
    "data=pd.DataFrame.from_dict(dict(x1),orient='index').reset_index().rename(index=str,columns={0:'value','index':'process_nodes'})\n",
    "data['angle'] = data['value']/sum(list(x1.values())) * 2*pi\n",
    "data['color'] = Category20c[len(x1)]\n",
    "p1 = figure(plot_height=350, title=\"Process Nodes\", toolbar_location=None,\n",
    "           tools=\"hover\", tooltips=\"@process_nodes: @value\")\n",
    "p1.wedge(x=0, y=1, radius=0.4,\n",
    "        start_angle=cumsum('angle', include_zero=True), end_angle=cumsum('angle'),\n",
    "        line_color=\"white\", fill_color='color', legend_field='process_nodes', source=data)\n",
    "p1.axis.axis_label=None\n",
    "p1.axis.visible=False\n",
    "p1.grid.grid_line_color = None \n",
    "show(column(p,p1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Database time evolution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SubtaskD1.d: Histogram\n",
    "# Task: Cumulative Histogram/ or line plot by ctime & mtime of all nodes over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# line plot by ctime & mtime\n",
    "\n",
    "ctimes = sorted(r[1] for r in res)\n",
    "mtimes = sorted(r[2] for r in res)\n",
    "num_nodes_integrated = range(len(ctimes))\n",
    "df = pd.DataFrame({'A':ctimes,\"B\":mtimes})\n",
    "\n",
    "#print(df.head())\n",
    "#df = pd.DataFrame({'A':np.random.randn(100).cumsum(),\"B\":np.random.randn(100).cumsum()})\n",
    "\n",
    "#plot multiline\n",
    "p = figure(plot_width=900, plot_height=300, x_axis_type='datetime')\n",
    "r=p.multi_line([df['A'], df['B']],  \n",
    "               [df.index, df.index],   \n",
    "               color=[\"firebrick\", \"navy\"],   \n",
    "               alpha=[0.8, 0.6],     \n",
    "               line_width=[2,1],     \n",
    "              )\n",
    "\n",
    "legend=Legend(items=[\n",
    "    LegendItem(label=\"ctime\",renderers=[r],index=0),\n",
    "    LegendItem(label=\"mtime\",renderers=[r],index=1),\n",
    "])\n",
    "p.add_layout(legend)\n",
    "p.xaxis.axis_label = 'Date'\n",
    "p.yaxis.axis_label = 'Number of nodes'\n",
    "\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Codes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SubtaskD1.e: Codes\n",
    "#Task: List Code names, sorted by by how many calcjobs where run with each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "codes = Code.objects.all()\n",
    "result = {code.label : len(code.get_outgoing(node_class=CalcJobNode).all_nodes()) for code in codes}\n",
    "result_df=pd.Series(result).sort_values(ascending=False)\n",
    "result_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Groups:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SubtaskD1.f: Groups\n",
    "#Task: List all group names with how many nodes they contain (verdi group list -C) (exclude import and export groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ListGroup(Group : list, exclude: list=[]):\n",
    "    \"\"\" return the group names and nodes they contain\n",
    "    \n",
    "    :the list of all groups\n",
    "    :the list of all excluded groups name\n",
    "    \"\"\"\n",
    "    print('{:<52}{:6}'.format('Group names:','sizes:'))\n",
    "    for a in Group:\n",
    "        flag=0\n",
    "        type = a[0].type_string\n",
    "        for ex in exclude:\n",
    "            if ex in type:\n",
    "                flag=1\n",
    "        if(flag):\n",
    "            continue     \n",
    "        else:\n",
    "            ## the line below contains all the properties\n",
    "            ##print(a[0].label,' ',a[0].user,' ',a[0].type_string,' ',a[0].description)\n",
    "\n",
    "            print('{:<50}|{:5}'.format(a[0].label,len(a[0].nodes)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load_profile()\n",
    "#!verdi group list --all\n",
    "from aiida.orm import QueryBuilder\n",
    "from aiida.orm import load_node, Node, Group, Computer, User, CalcJobNode, Code, StructureData\n",
    "\n",
    "qb = QueryBuilder()\n",
    "qb.append(Group)\n",
    "#print(qb.all())\n",
    "\n",
    "group = qb.all()\n",
    "ListGroup(group,exclude=['export','import'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Structure Analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SubtaskD1.g: Structures\n",
    "a = '''\n",
    "Task: Further analyze what structures are in the DB\n",
    "\n",
    "Number of structureData node versus how many atoms they contain. \n",
    "\n",
    "here interactive with bokeh hover tool showing the structure formula and uuid\n",
    "\n",
    "Number of StructureData nodes versus elements bokeh bar chart, since there are over \n",
    "100 elements in the periodic table you can split it over several plots, or just use the charge number as in \n",
    "'example/element_content.png' but then make it interactive that once one hovers \n",
    "with the mouse over a bar it tells you what element it is and how many structures there are containing this element-\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aiida.orm import QueryBuilder\n",
    "from aiida.orm import load_node, Node, Group, Computer, User, CalcJobNode, Code, StructureData\n",
    "from HelperPackage import DataProcessing\n",
    "from DataProcessing.DataVisu import StrucDataForm\n",
    "\n",
    "def NumStructureNode():\n",
    "    #### return the pd.DataFrame including elements and number of each element\n",
    "    import pandas as pd\n",
    "    StrucList = []\n",
    "    qb = QueryBuilder()\n",
    "    qb.append(StructureData)\n",
    "    print('number of StructureData Nodes:',qb.count())\n",
    "    qb.count()\n",
    "\n",
    "    for struc, in qb.all()[:]:\n",
    "        form = struc.get_formula()\n",
    "        struct = StrucDataForm(form)\n",
    "        StrucList = StrucList+ [struct.FormAnalyse()]\n",
    "    return pd.DataFrame(StrucList).fillna(0)\n",
    "\n",
    "def ShowElements(Data):\n",
    "    from bokeh.io import output_file, show\n",
    "    from bokeh.models import ColumnDataSource,HoverTool\n",
    "    from bokeh.plotting import figure\n",
    "    from bokeh.io import output_notebook\n",
    "    from bokeh.palettes import inferno\n",
    "\n",
    "    output_file(\"ShowingElements.html\")\n",
    "    #data = NumStructureNode()\n",
    "    data = Data\n",
    "    elements = list(data.columns)\n",
    "    counts = list(data.astype(bool).sum(axis=0))\n",
    "    #print(counts)\n",
    "    #print(elements)\n",
    "    \n",
    "    source = ColumnDataSource(data=dict(elements=elements, counts=counts,color=inferno(len(elements))))\n",
    "    \n",
    "    TOOLTIPS = [\n",
    "    (\"element\", \"@elements\"),\n",
    "    (\"(x,y)\", \"($x, $y)\"),\n",
    "    (\"Number of Structures containing this element\", \"@counts\"),\n",
    "    ]\n",
    "\n",
    "    p = figure( y_range=elements,x_range=(0,500), plot_width=800, plot_height=800, title=\"Elements Counts\",tools = [HoverTool(mode='hline')], tooltips=TOOLTIPS)\n",
    "    #print('step figure done')\n",
    "    p.hbar(y=\"elements\", right=\"counts\", height=0.5, left=0, color='color',  source=source)\n",
    "    #print('step hbar done')\n",
    "    \n",
    "    output_notebook()\n",
    "    p.xgrid.grid_line_color = None\n",
    "    #p.legend = False\n",
    "    show(p)\n",
    "    \n",
    "    \n",
    "def ShowFormula(Data):\n",
    "    from bokeh.io import output_file, show\n",
    "    from bokeh.models import ColumnDataSource,HoverTool\n",
    "    from bokeh.plotting import figure\n",
    "    from bokeh.io import output_notebook\n",
    "    from bokeh.palettes import inferno\n",
    "\n",
    "    data = Data\n",
    "    elements = list(data.keys())\n",
    "    counts = list(len(data[key])/2 for key in data.keys())\n",
    "    formulas = list(data[key] for key in data.keys())\n",
    "\n",
    "    length = len(elements)\n",
    "    source = ColumnDataSource(data=dict(elements=elements, counts=counts,formulas=formulas,color=inferno(length)))\n",
    "    \n",
    "    TOOLTIPS = [\n",
    "    (\"Number of Atoms\", \"@elements\"),\n",
    "    (\"(x,y)\", \"($x, $y)\"),\n",
    "    (\"Number of Nodes\", \"@counts\"),\n",
    "    (\"id and formula\", \"@formulas\"),\n",
    "    ]\n",
    "\n",
    "    p = figure( y_range=(0,160),x_range=(0,1000), plot_width=800, plot_height=800, title=\"Atoms Count\",tools = [HoverTool(mode='hline')], tooltips=TOOLTIPS)\n",
    "    #print('step figure done')\n",
    "    p.hbar(y=\"elements\", right=\"counts\", height=0.5, left=0, color='color',  source=source)\n",
    "    #print('step hbar done')\n",
    "    \n",
    "    output_notebook()\n",
    "    p.xgrid.grid_line_color = None\n",
    "    #p.legend = False\n",
    "    show(p)\n",
    "    \n",
    "def GetFormulaDict():\n",
    "    ## may be not necessary, return the formulas and nodes containing this formula\n",
    "    import numpy as np\n",
    "    from aiida.orm import QueryBuilder,StructureData\n",
    "    qb = QueryBuilder()\n",
    "    qb.append(StructureData)\n",
    "    Mydict = qb.all()\n",
    "    Mydict = np.ravel(Mydict)\n",
    "\n",
    "    Newdict = {}\n",
    "    for dict in Mydict:\n",
    "        if dict.get_formula in Newdict.keys():\n",
    "            Newdict[dict.get_formula()].append(dict.uuid)\n",
    "        else:\n",
    "            Newdict[dict.get_formula()] = [dict.uuid]\n",
    "    return Newdict\n",
    "\n",
    "def AtomsNumNodes():\n",
    "    from aiida.orm import QueryBuilder,StructureData\n",
    "    import numpy as np\n",
    "    qb = QueryBuilder()\n",
    "    qb.append(StructureData)\n",
    "    StructDatas = qb.all()\n",
    "    Newdict = {}\n",
    "    \n",
    "    for data, in StructDatas:\n",
    "        CompositionDict = data.get_composition()\n",
    "        NumAtom = np.sum(list(CompositionDict.values()))\n",
    "        if NumAtom in Newdict.keys():\n",
    "            Newdict[NumAtom].append(data.uuid)\n",
    "            Newdict[NumAtom].append(data.get_formula())\n",
    "        else:\n",
    "            Newdict[NumAtom] = [data.uuid,data.get_formula()]\n",
    "    return Newdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic = AtomsNumNodes()\n",
    "ShowFormula(dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = NumStructureNode()\n",
    "ShowElements(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the Structure data\n",
    "from aiida.orm import QueryBuilder\n",
    "from aiida.orm import load_node, Node, Group, Computer, User, CalcJobNode, Code, StructureData\n",
    "from HelperPackage import DataProcessing\n",
    "from DataProcessing.DataVisu import StrucDataForm\n",
    "\n",
    "qb = QueryBuilder()\n",
    "qb.append(StructureData)\n",
    "\n",
    "structures = qb.all()\n",
    "\n",
    "for structure in structures[:]:\n",
    "    formula = structure[0].get_formula()\n",
    "    struct = StrucDataForm(formula)\n",
    "    structure[0].get_composition()\n",
    "    print(struct.FormAnalyse())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SubtaskD1.h: Calculations\n",
    "a = '''\n",
    "Task: more detail analysis of Calculations\n",
    "\n",
    "`print('\\n\\nMore detailed analysis of Calculations \\n')`\n",
    "\n",
    "List, stacked Histogram of Calculations types and the state it ended up finished, failed, exit codes, exit messages\n",
    "\n",
    "more detail analysis of WorkChains\n",
    "\n",
    "`print('\\n\\nMore detailed analysis of WorkChains \\n')`\n",
    "\n",
    "List,  stacked Histogram for each Workchain type and the state it ended up in finished, failed, exit codes, exit messages\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetCalNode():\n",
    "    exit_state = []\n",
    "    exit_message = []\n",
    "    index = []\n",
    "    exit_state_digit = []\n",
    "    for node, in CalcNode:\n",
    "        print(str(node.process_state))\n",
    "        print(node.pk)\n",
    "        #print(str(node.exit_message))\n",
    "        exit_state = exit_state + [str(node.process_state)]\n",
    "        exit_message = exit_message + [str(node.exit_message)]\n",
    "        index = index + [node.pk]\n",
    "        if node.is_finished_ok:\n",
    "            exit_state_digit = exit_state_digit + [1]\n",
    "        else:\n",
    "            exit_state_digit = exit_state_digit + [0]\n",
    "    return exit_state,exit_message,index,exit_state_digit\n",
    "\n",
    "def ShowCalNode(exit_state,exit_message,index,exit_state_digit):\n",
    "    from bokeh.io import output_file, show\n",
    "    from bokeh.models import ColumnDataSource\n",
    "    from bokeh.plotting import figure\n",
    "    from bokeh.io import output_notebook\n",
    "    from bokeh.palettes import inferno\n",
    "\n",
    "    output_file(\"ShowingCal.html\")\n",
    "\n",
    "    index = index\n",
    "    exit_message = exit_message\n",
    "    exit_state_string = exit_state\n",
    "    exit_state_digit = exit_state_digit\n",
    "      \n",
    "    source = ColumnDataSource(data=dict(index=index, exit_state_digit=exit_state_digit,exit_message = exit_message,exit_state_string = exit_state_string, color=inferno(len(index))))\n",
    "    \n",
    "    TOOLTIPS = [\n",
    "    (\"Exit information\", \"@exit_message\"),\n",
    "    (\"(x,y)\", \"($x, $y)\"),\n",
    "    (\"Node index\", \"@index\"),\n",
    "    (\"Node status\", \"@exit_state_string\"),   \n",
    "    ]\n",
    "\n",
    "    p = figure( y_range=(0,1), x_range=(0,3000), plot_width=800, plot_height=800, title=\"CalcNode Information\", tooltips=TOOLTIPS)\n",
    "    #print('step figure done')\n",
    "    p.vbar(x=\"index\", top=\"exit_state_digit\", bottom=0, width=1, color='color',  source=source)\n",
    "    #print('step hbar done')\n",
    "    \n",
    "    output_notebook()\n",
    "    p.xgrid.grid_line_color = None\n",
    "    #p.legend = False\n",
    "    show(p)\n",
    "    \n",
    "def GetWorkflowNode(Name):\n",
    "    from aiida.orm import WorkflowNode\n",
    "    from aiida.orm import QueryBuilder\n",
    "    qb = QueryBuilder()\n",
    "    qb.append(Name)\n",
    "    WNode = qb.all()\n",
    "\n",
    "    Newdict = {}\n",
    "    for node, in WNode:\n",
    "        if node.is_finished_ok:\n",
    "            Newdict[node.node_type+'_succeed'] = Newdict.get(node.node_type+'_succeed',0) + 1\n",
    "            Newdict[node.node_type+'_not_succeed'] = Newdict.get(node.node_type+'_not_succeed',0) + 0\n",
    "        else:\n",
    "            Newdict[node.node_type+'_not_succeed'] = Newdict.get(node.node_type+'_not_succeed',0) + 1\n",
    "            Newdict[node.node_type+'_succeed'] = Newdict.get(node.node_type+'_succeed',0) + 0\n",
    "    return Newdict\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from aiida.orm import CalcJobNode\n",
    "from aiida.orm import QueryBuilder\n",
    "qb = QueryBuilder()\n",
    "qb.append(CalcJobNode)\n",
    "CalcNode = qb.all()\n",
    "\n",
    "exit_state,exit_message,index,exit_state_digit = GetCalNode()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ShowCalNode(exit_state,exit_message,index,exit_state_digit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Newdict1 = GetWorkflowNode(WorkflowNode)\n",
    "Newdict2 = GetWorkflowNode(CalcJobNode)\n",
    "print(Newdict1)\n",
    "print(Newdict2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ShowWorkflow(WorkflowDict):\n",
    "    from bokeh.io import output_file, show\n",
    "    from bokeh.models import ColumnDataSource,HoverTool\n",
    "    from bokeh.plotting import figure\n",
    "    from bokeh.io import output_notebook\n",
    "    from bokeh.palettes import inferno\n",
    "\n",
    "    output_file(\"ShowingCal.html\")\n",
    "\n",
    "    index = list(WorkflowDict.keys())\n",
    "    counts = list(WorkflowDict.values())\n",
    "    #exit_message = exit_message\n",
    "    #exit_state_string = exit_state\n",
    "    #exit_state_digit = exit_state_digit\n",
    "      \n",
    "    source = ColumnDataSource(data=dict(index=index, counts=counts, color=inferno(len(index))))\n",
    "    \n",
    "    TOOLTIPS = [\n",
    "    (\"Node number\", \"@counts\"),\n",
    "    (\"(x,y)\", \"($x, $y)\"),\n",
    "    (\"Node status\", \"@index\"),   \n",
    "    ]\n",
    "   \n",
    "    HT = HoverTool(\n",
    "    tooltips=TOOLTIPS,\n",
    "\n",
    "    mode='vline'\n",
    "    )\n",
    "    \n",
    "    p = figure( y_range=(0,50), x_range=index, plot_width=800, plot_height=800, title=\"Process Node Information\",tools = [HoverTool(mode='vline')],tooltips=TOOLTIPS)\n",
    "    #print('step figure done')\n",
    "    p.vbar(x=\"index\", top=\"counts\", bottom=0, width=1, color='color',  source=source)\n",
    "    #print('step hbar done')\n",
    "    \n",
    "    output_notebook()\n",
    "    p.xgrid.grid_line_color = None\n",
    "    #p.legend = False\n",
    "    show(p)\n",
    "\n",
    "ShowWorkflow(Newdict1)\n",
    "ShowWorkflow(Newdict2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data provenance health indicators:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# SubtaskD1.i: Provenance\n",
    "#Task: Database and provenance health: display the number of nodes who have no incomming and outgoing links, no incomming links (any number outgoing), and no outgoing links (any number incomming)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Count_In_Out():\n",
    "    from aiida.orm import QueryBuilder\n",
    "    qb = QueryBuilder()\n",
    "    qb.append(Node)\n",
    "    Nodes = qb.all()\n",
    "    Namelist = ['No_Incoming','No_Outgoing','No_In&Out']\n",
    "\n",
    "    Mydict = {}\n",
    "    for n, in Nodes:\n",
    "        Incoming_flag,Outgoingflag = False,False\n",
    "        if(n.get_incoming().all_nodes() == []):\n",
    "            Incoming_flag = True\n",
    "            Mydict[Namelist[0]] = Mydict.get(Namelist[0],0)+1\n",
    "        if(n.get_outgoing().all_nodes() == []):\n",
    "            Outgoingflag = True\n",
    "            Mydict[Namelist[1]] = Mydict.get(Namelist[1],0)+1\n",
    "        if(Incoming_flag and Outgoingflag):\n",
    "            Mydict[Namelist[2]] = Mydict.get(Namelist[2],0)+1\n",
    "\n",
    "    return Mydict\n",
    "\n",
    "def Show_In_Out(Mydict):\n",
    "    from bokeh.io import output_file, show\n",
    "    from bokeh.models import ColumnDataSource,HoverTool\n",
    "    from bokeh.plotting import figure\n",
    "    from bokeh.io import output_notebook\n",
    "    from bokeh.palettes import Category20\n",
    "\n",
    "    output_file(\"Show_In_Out.html\")\n",
    "\n",
    "    index = list(Mydict.keys())\n",
    "    counts = list(Mydict.values())\n",
    "      \n",
    "    source = ColumnDataSource(data=dict(index=index, counts=counts, color=Category20[len(index)]))\n",
    "    \n",
    "    TOOLTIPS = [\n",
    "    (\"Node number\", \"@counts\"),\n",
    "    (\"(x,y)\", \"($x, $y)\"),\n",
    "    (\"Node status\", \"@index\"),   \n",
    "    ]\n",
    "   \n",
    "    HT = HoverTool(\n",
    "    tooltips=TOOLTIPS,\n",
    "\n",
    "    mode='vline'\n",
    "    )\n",
    "    \n",
    "    p = figure( y_range=(0,6000), x_range=index, plot_width=800, plot_height=800, title=\"CalcNode Information\",tools = [HoverTool(mode='vline')],tooltips=TOOLTIPS)\n",
    "    #print('step figure done')\n",
    "    p.vbar(x=\"index\", top=\"counts\", bottom=0, width=1, color='color',  source=source)\n",
    "    #print('step hbar done')\n",
    "    \n",
    "    output_notebook()\n",
    "    p.xgrid.grid_line_color = None\n",
    "    #p.legend = False\n",
    "    show(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Mydict = Count_In_Out()\n",
    "print(Mydict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Show_In_Out(Mydict)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Hide code",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "12px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
