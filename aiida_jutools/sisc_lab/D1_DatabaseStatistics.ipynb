{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistical birds eye view of the contents in an AiiDAdb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the first of two deliverable for the SiSc-Lab2020 project.\n",
    "\n",
    "Authors = Miao Wang(2. - 2.4), Zhipeng Tan(2.5 - 3.)\n",
    "\n",
    "Supervisors: Dr. Jens Bröder, Dr. Daniel Wortmann, Johannes Wasmer, Prof. Dr. Stefan Blügel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Usage: adjust user constants in code cell 'User constants'.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# User constants\n",
    "aiida_profile_name = \"wasmer\"\n",
    "enable_autoreload = True # disable for timings\n",
    "\n",
    "# for timings file\n",
    "# to get database_size: \n",
    "#   1) in terminal, type 'verdi profile show'. note down aiidadb_name.\n",
    "#   2) in terminal, type 'psql', then '\\l+'. note down db size from table. exit with '\\q'.\n",
    "notebook_name = \"D1\"\n",
    "database_name = \"wasmer_medium_size\"\n",
    "database_size = 431 # MB\n",
    "database_description = [\n",
    "    \"800 Impurity (defect atoms) embeddings into different elemental host crystals with aiida-kkr.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if enable_autoreload:\n",
    "    %load_ext autoreload\n",
    "    %autoreload 2\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# python imports:\n",
    "import time\n",
    "import json\n",
    "#from pprint import pprint\n",
    "\n",
    "#%pylab inline\n",
    "#figuresize=(18, 4)\n",
    "from collections import Counter\n",
    "from math import pi\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "from bokeh.io import output_file,output_notebook, show\n",
    "from bokeh.layouts import column\n",
    "from bokeh.palettes import Category20,Category20c,Spectral11\n",
    "from bokeh.plotting import figure,ColumnDataSource\n",
    "from bokeh.transform import cumsum\n",
    "from bokeh.models import Legend,LegendItem,HoverTool,ColumnDataSource\n",
    "# init bokeh\n",
    "output_notebook()\n",
    "\n",
    "# aiida imports:\n",
    "from aiida import load_profile\n",
    "profile = load_profile(aiida_profile_name)\n",
    "\n",
    "# ggf add futher imports\n",
    "from aiida.orm import QueryBuilder as QB\n",
    "from aiida.orm import QueryBuilder\n",
    "from aiida.orm import WorkflowNode\n",
    "from aiida.orm import load_node, Node, Group, Computer,Dict\n",
    "from aiida.orm import User, CalcJobNode, Code, StructureData, ProcessNode\n",
    "from aiida.plugins import DataFactory\n",
    "from aiida.common.constants import elements as PeriodicTableElements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # project imports prep (for johannes, else comment out)\n",
    "\n",
    "# # add project module to sys.path\n",
    "# import sys\n",
    "# from pathlib import Path\n",
    "\n",
    "# def add_to_sys_path(path:Path):\n",
    "#     if str(path) not in sys.path:\n",
    "#         sys.path.append(str(path))\n",
    "\n",
    "# # load developer's code: general package\n",
    "# project_dir = Path(\"/Users/wasmer/src/aiida-jutools/\")\n",
    "# add_to_sys_path(project_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# project imports:\n",
    "#import helpers\n",
    "# if this does not work, do a `pip install -e .` in the aiida-jutools head folder\n",
    "from aiida_jutools.sisc_lab import helpers\n",
    "\n",
    "\n",
    "import aiida_jutools.sisc_lab.util.data_visu as DV\n",
    "import aiida_jutools.sisc_lab.util.serialization as SR\n",
    "from aiida_jutools.sisc_lab.util.data_visu import AnalyseStructureElements,ShowElements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init timer for timings:\n",
    "timer = helpers.Timer(notebook_name=notebook_name, \n",
    "                      database_name=database_name,\n",
    "                      database_size=database_size)\n",
    "timer.DATABASE_DESCRIPTION = database_description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "helpers.print_bold(f\"This notebook/dashboard will visualize the contents from the database of profile {profile.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Database overview:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timing_name = \"Database overview\"\n",
    "timer.start(timing_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query for all nodes\n",
    "print('Information on nodes in the DB: \\n')\n",
    "now = time.strftime(\"%c\")\n",
    "print('last executed on {}'.format(now))\n",
    "q = QB()\n",
    "q.append(Node, project=['id', 'ctime', 'mtime', 'node_type'], tag='node')\n",
    "q.append(User, with_node='node', project='email')\n",
    "# TODO: execute query here\n",
    "t = time.time()\n",
    "res = q.all()\n",
    "elapsed = time.time() - t\n",
    "totalnodes = len(res)\n",
    "print(\"Total number of nodes in the database: {} (retrieved in {} s.)\".format(totalnodes, elapsed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timer.stop(timing_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User information:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timing_name = \"User information\"\n",
    "timer.start(timing_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Users:\")\n",
    "helpers.print_Count('user',res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timer.stop(timing_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Node types distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timing_name = \"Node types\"\n",
    "timer.start(timing_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Node types:\")\n",
    "helpers.print_Count('types',res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split data nodes and process nodes\n",
    "types = Counter([r[3] for r in res])\n",
    "node_count = helpers.get_data_node_count(types,'data') \n",
    "p = helpers.draw_pie_chart(node_count,'Data Nodes:%s')\n",
    "\n",
    "process_count = helpers.get_process_node_count(types,'process')\n",
    "p1 = helpers.draw_pie_chart(process_count,'Process Nodes:%s')\n",
    "\n",
    "show(column(p,p1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = helpers.draw_pie_chart(Counter(helpers.get_dict_link_types()),'Dict Link Types:%s')\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timer.stop(timing_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Database time evolution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timing_name = \"Database evolution\"\n",
    "timer.start(timing_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = Counter([r[4] for r in res])\n",
    "output_notebook()\n",
    "helpers.draw_line_plot(users,res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timer.stop(timing_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Codes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timing_name = \"Codes analysis\"\n",
    "timer.start(timing_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "codes = Code.objects.all()\n",
    "result = {code.full_label: len(code.get_outgoing(node_class=CalcJobNode).all_nodes()) for code in codes}\n",
    "#result_df=pd.Series(result).sort_values(ascending=False)\n",
    "result_df=pd.DataFrame({'code@computer':result.keys(),'CalaJobcount':result.values()}).sort_values(by='CalaJobcount',ascending=False).reset_index(drop=True)\n",
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timer.stop(timing_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Groups:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timing_name = \"Groups analysis\"\n",
    "timer.start(timing_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    Groups_data = SR.deserialize_from_file('./output/group.json',Node_type='Group')\n",
    "except (FileNotFoundError, ValueError) as err:\n",
    "    qb = QueryBuilder()\n",
    "    qb.append(Group)\n",
    "    group = qb.all()\n",
    "\n",
    "    #data = GroupDataHelper(group)\n",
    "    #data.ListGroup(exclude=['export','import'])\n",
    "\n",
    "    ### add more columns for this and do also for other nodes\n",
    "    serializer = SR.Serializer(group)\n",
    "    serializer.to_file('./output/group.json',Node_type='Group')\n",
    "    Groups_data = SR.deserialize_from_file('./output/group.json',Node_type='Group')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qb = QueryBuilder()\n",
    "qb.append(Group)\n",
    "group = qb.all()\n",
    "group[0][0].__dict__\n",
    "s = dir(group[0][0])\n",
    "s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group[0][0].count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Groups_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = DV.GroupDataHelper(Groups_data)\n",
    "data.ListGroup(exclude=['export','import'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timer.stop(timing_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Structure Analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timing_name = \"Structures analysis\"\n",
    "timer.start(timing_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    filepath = './output/Num_structure.json'\n",
    "    Newdata = SR.deserialize_from_file(filepath,Node_type = 'StructureFormula')\n",
    "except:\n",
    "    ################### serialization\n",
    "    qb = QueryBuilder()\n",
    "    qb.append(StructureData)\n",
    "    StructDatas = qb.all()\n",
    "\n",
    "    #print(dic.keys())\n",
    "\n",
    "    serializer = SR.Serializer(StructDatas)\n",
    "    filepath = './output/Num_structure.json'\n",
    "    serializer.to_file(filepath ,Node_type='StructureFormula')\n",
    "    Newdata = SR.deserialize_from_file(filepath,Node_type = 'StructureFormula')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    filepath = './output/StructDataGeneral.json'\n",
    "    dataF = SR.deserialize_from_file(filepath,Node_type = 'StructureGeneral')\n",
    "except:\n",
    "    qb = QueryBuilder()\n",
    "    qb.append(StructureData)\n",
    "    StructDatas = qb.all()\n",
    "    filepath = './output/StructDataGeneral.json'\n",
    "    serializer = SR.Serializer(StructDatas)\n",
    "    serializer.to_file(filepath,'StructureGeneral')\n",
    "    dataF = SR.deserialize_from_file(filepath,Node_type = 'StructureGeneral')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DV.ShowFormula(Newdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    filepath = './output/Struct_Element.json'\n",
    "    x = SR.deserialize_from_file(filepath,'StructureElement')\n",
    "    \n",
    "except:\n",
    "    qb = QueryBuilder()\n",
    "    qb.append(StructureData)\n",
    "    StructDatas = qb.all()\n",
    "    serializer = SR.Serializer(StructDatas)\n",
    "    filepath = './output/Struct_Element.json'\n",
    "    serializer.to_file(filepath,'StructureElement')\n",
    "    x = SR.deserialize_from_file(filepath,'StructureElement')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ShowElements(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timer.stop(timing_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timing_name = \"Processes info\"\n",
    "timer.start(timing_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "####### CalcNode \n",
    "try:\n",
    "    filepath = './output/CalcNode.json'\n",
    "    calcArray = SR.deserialize_from_file(filepath,Node_type = 'ProcessNode')\n",
    "except:  \n",
    "    qb = QueryBuilder()\n",
    "    qb.append(CalcJobNode)\n",
    "    CalcNode = qb.all()\n",
    "\n",
    "    serializer = SR.Serializer(CalcNode)\n",
    "    filepath = './output/CalcNode.json'\n",
    "    serializer.to_file(filepath,'ProcessNode')\n",
    "    calcArray = SR.deserialize_from_file(filepath,Node_type = 'ProcessNode')\n",
    "\n",
    "######## WorkflowNode\n",
    "try:\n",
    "    filepath2 = './output/WorkflowNode.json'\n",
    "    WorkflowArray = SR.deserialize_from_file(filepath2,Node_type = 'ProcessNode')\n",
    "except:\n",
    "    qb = QueryBuilder()\n",
    "    qb.append(WorkflowNode)\n",
    "    WorkflowNodes = qb.all()\n",
    "\n",
    "    serializer = SR.Serializer(WorkflowNodes)\n",
    "    filepath2 = './output/WorkflowNode.json'\n",
    "    serializer.to_file(filepath2,'ProcessNode')\n",
    "    WorkflowArray = SR.deserialize_from_file(filepath2,Node_type = 'ProcessNode')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qb = QueryBuilder()\n",
    "qb.append(CalcJobNode)\n",
    "CalcNode = qb.all()\n",
    "dir(CalcNode[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calcArray.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WorkflowArray.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Newdict1 = DV.GetWorkflowDict(WorkflowArray)\n",
    "Newdict2 = DV.GetWorkflowDict(calcArray)\n",
    "DV.ShowWorkflow(Newdict1,'Work Flow Node Information')\n",
    "DV.ShowWorkflow(Newdict2,'Calculate Job Node Information')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timer.stop(timing_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data provenance health indicators:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timing_name = \"Provenance analysis\"\n",
    "timer.start(timing_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## this cell will take some time,but after the preprocessing everything should be fine\n",
    "try:\n",
    "    filepath = './output/provenance.json'\n",
    "    provenance = SR.deserialize_from_file(filepath,'Provenance')\n",
    "except:\n",
    "    qb = QueryBuilder()\n",
    "    qb.append(Node)\n",
    "    Nodes = qb.all()\n",
    "\n",
    "    #### serialization to filepath\n",
    "    provenance_serializer = SR.Serializer(Nodes)\n",
    "    filepath = './output/provenance.json'\n",
    "    provenance_serializer.to_file(filepath,'Provenance')\n",
    "    provenance = SR.deserialize_from_file(filepath,'Provenance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### deserialization from filepath\n",
    "provenance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "No_Incoming_Mydict,No_Outgoing_Mydict,No_InOut_Mydict = DV.Count_In_Out(provenance)\n",
    "print(No_Incoming_Mydict,No_Outgoing_Mydict,No_InOut_Mydict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DV.Show_In_Out(No_Incoming_Mydict,No_Outgoing_Mydict,No_InOut_Mydict)\n",
    "### split and think about bar plot\n",
    "# reduce complexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timer.stop(timing_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################\n",
    "# save timings\n",
    "timer.save(silent=False)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Hide code",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "12px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
